{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Data606_MovieLens.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3.9.2 64-bit",
      "metadata": {
        "interpreter": {
          "hash": "ee5cc6fef2d70a7e71ee3826687cbd150f18158e0b1eef11d4f4f92bb920e304"
        }
      }
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Z4N9SH7gix9c"
      },
      "source": [
        "# Data 606 - Capstone Project\r\n",
        "###Movie Recommendation System"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TMy3R_w3i4lz"
      },
      "source": [
        "Goal of this project: To explore recommendation system on the movie dataset with both content-based method and collaborative method using Machine Learning Algorithms. \r\n",
        "\r\n",
        "Outline for this project:\r\n",
        "1. EDA\r\n",
        "2. Data prep. \r\n",
        "3. Content-based Classfication\r\n",
        "4. Collaborative filtering"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tAwxmrm0jCDo"
      },
      "source": [
        "#### **About the Dataset:**\r\n",
        "This dataset (ml-latest-small) describes 5-star rating and free-text tagging activity from MovieLens, a movie recommendation service. It contains 100836 ratings and 3683 tag applications across 9742 movies. These data were created by 610 users between March 29, 1996 and September 24, 2018. This dataset was generated on September 26, 2018.\r\n",
        "\r\n",
        "Users were selected at random for inclusion. All selected users had rated at least 20 movies. No demographic information is included. Each user is represented by an id, and no other information is provided.\r\n",
        "\r\n",
        "The data are contained in the files links.csv, movies.csv, ratings.csv and tags.csv. More details about the contents and use of all these files follows.\r\n",
        "\r\n",
        "#### **User Ids**\r\n",
        "MovieLens users were selected at random for inclusion. Their ids have been anonymized. User ids are consistent between ratings.csv and tags.csv (i.e., the same id refers to the same user across the two files).\r\n",
        "\r\n",
        "#### **Movie Ids**\r\n",
        "Only movies with at least one rating or tag are included in the dataset. These movie ids are consistent with those used on the MovieLens web site (e.g., id 1 corresponds to the URL https://movielens.org/movies/1). Movie ids are consistent between ratings.csv, tags.csv, movies.csv, and links.csv (i.e., the same id refers to the same movie across these four data files).\r\n",
        "\r\n",
        "#### **Ratings Data**\r\n",
        "Each line of this file after the header row represents one rating of one movie by one user, and has the following format:\r\n",
        "\r\n",
        "userId,movieId,rating,timestamp\r\n",
        "\r\n",
        "Ratings are made on a 5-star scale, with half-star increments (0.5 stars - 5.0 stars).\r\n",
        "\r\n",
        "Timestamps represent seconds since midnight Coordinated Universal Time (UTC) of January 1, 1970.\r\n",
        "\r\n",
        "#### **Tags Data**\r\n",
        "\r\n",
        "Each line of this file after the header row represents one tag applied to one movie by one user, and has the following format:\r\n",
        "\r\n",
        "userId,movieId,tag,timestamp\r\n",
        "\r\n",
        "Tags are user-generated metadata about movies. Each tag is typically a single word or short phrase. The meaning, value, and purpose of a particular tag is determined by each user.\r\n",
        "\r\n",
        "Timestamps represent seconds since midnight Coordinated Universal Time (UTC) of January 1, 1970.\r\n",
        "\r\n",
        "\r\n",
        "#### **Movies Data**\r\n",
        "Each line of this file after the header row represents one movie, and has the following format:\r\n",
        "\r\n",
        "movieId,title,genres\r\n",
        "Genres are a pipe-separated list, and are selected from the following:\r\n",
        "\r\n",
        "Action\r\n",
        "Adventure\r\n",
        "Animation\r\n",
        "Children's\r\n",
        "Comedy\r\n",
        "Crime\r\n",
        "Documentary\r\n",
        "Drama\r\n",
        "Fantasy\r\n",
        "Film-Noir\r\n",
        "Horror\r\n",
        "Musical\r\n",
        "Mystery\r\n",
        "Romance\r\n",
        "Sci-Fi\r\n",
        "Thriller\r\n",
        "War\r\n",
        "Western\r\n",
        "(no genres listed)\r\n",
        "\r\n",
        "#### **Links Data**\r\n",
        "Identifiers that can be used to link to other sources of movie data are contained in the file links.csv. Each line of this file after the header row represents one movie, and has the following format:\r\n",
        "\r\n",
        "movieId,imdbId,tmdbId\r\n",
        "\r\n",
        "movieId is an identifier for movies used by https://movielens.org. E.g., the movie Toy Story has the link https://movielens.org/movies/1.\r\n",
        "\r\n",
        "imdbId is an identifier for movies used by http://www.imdb.com. E.g., the movie Toy Story has the link http://www.imdb.com/title/tt0114709/.\r\n",
        "\r\n",
        "tmdbId is an identifier for movies used by https://www.themoviedb.org. E.g., the movie Toy Story has the link https://www.themoviedb.org/movie/862.\r\n",
        "\r\n",
        "#### **References:**\r\n",
        "F. Maxwell Harper and Joseph A. Konstan. 2015. The MovieLens Datasets: History and Context. ACM Transactions on Interactive Intelligent Systems (TiiS) 5, 4: 19:1â€“19:19. https://doi.org/10.1145/2827872"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "R4auh59zjBer"
      },
      "source": [
        "#Import Required Libraries\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import os\n",
        "from pyspark.sql import SparkSession\n",
        "from pyspark.conf import SparkConf\n",
        "from pyspark.sql.functions import isnan, when, count, col\n",
        "from pyspark.sql.functions import to_timestamp\n",
        "from pyspark.sql import functions as f\n",
        "from pyspark.sql import types as t\n",
        "\n",
        "\n"
      ],
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {},
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<module 'numpy.version' from 'C:\\\\Python\\\\Python39\\\\lib\\\\site-packages\\\\numpy\\\\version.py'>"
            ]
          },
          "metadata": {},
          "execution_count": 3
        }
      ],
      "source": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vjvQxgqciQFV"
      },
      "source": [
        "spark = SparkSession \\\n",
        "    .builder \\\n",
        "    .appName(\"Data_606_Project\") \\\n",
        "    .config(conf=SparkConf()) \\\n",
        "    .getOrCreate()"
      ],
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "r02oxNr1liEo"
      },
      "source": [
        "path = 'C:\\\\Users\\\\kamho\\\\OneDrive\\\\Documents\\\\GitHub\\\\movieRecommendationSystem\\\\MRS_repo\\\\data\\\\raw\\\\Data3_movielens\\\\'"
      ],
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "b-gN17GJliHs"
      },
      "source": [
        "df_links = spark.read.csv(path+'links.csv', header=True,inferSchema='true')\n",
        "df_movies = spark.read.csv(path+'movies.csv',header=True,inferSchema='true')\n",
        "df_ratings = spark.read.csv(path+'ratings.csv', header=True,inferSchema='true')\n",
        "df_tags = spark.read.csv(path+'tags.csv', header=True,inferSchema='true')"
      ],
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mB-OvSP2liJy"
      },
      "source": [
        "#Create a Dictionary for running functions conveniently.\n",
        "df_dict = {'df_links' : df_links, 'df_movies':df_movies, 'df_ratings':df_ratings, 'df_tags':df_tags}"
      ],
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jUG6hn6yliMV",
        "outputId": "17d54b39-af14-43f2-db83-a28f1a757ffa"
      },
      "source": [
        "#Counting total no. of records of each dataframes\n",
        "for name, df in df_dict.items():\n",
        "  \n",
        "  print(name)\n",
        "  df.show()\n",
        "  print('Total Records in',name,':',df.count())\n",
        "  print('')"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "df_links\n",
            "+-------+------+------+\n",
            "|movieId|imdbId|tmdbId|\n",
            "+-------+------+------+\n",
            "|      1|114709|   862|\n",
            "|      2|113497|  8844|\n",
            "|      3|113228| 15602|\n",
            "|      4|114885| 31357|\n",
            "|      5|113041| 11862|\n",
            "|      6|113277|   949|\n",
            "|      7|114319| 11860|\n",
            "|      8|112302| 45325|\n",
            "|      9|114576|  9091|\n",
            "|     10|113189|   710|\n",
            "|     11|112346|  9087|\n",
            "|     12|112896| 12110|\n",
            "|     13|112453| 21032|\n",
            "|     14|113987| 10858|\n",
            "|     15|112760|  1408|\n",
            "|     16|112641|   524|\n",
            "|     17|114388|  4584|\n",
            "|     18|113101|     5|\n",
            "|     19|112281|  9273|\n",
            "|     20|113845| 11517|\n",
            "+-------+------+------+\n",
            "only showing top 20 rows\n",
            "\n",
            "Total Records in df_links : 9742\n",
            "\n",
            "df_movies\n",
            "+-------+--------------------+--------------------+\n",
            "|movieId|               title|              genres|\n",
            "+-------+--------------------+--------------------+\n",
            "|      1|    Toy Story (1995)|Adventure|Animati...|\n",
            "|      2|      Jumanji (1995)|Adventure|Childre...|\n",
            "|      3|Grumpier Old Men ...|      Comedy|Romance|\n",
            "|      4|Waiting to Exhale...|Comedy|Drama|Romance|\n",
            "|      5|Father of the Bri...|              Comedy|\n",
            "|      6|         Heat (1995)|Action|Crime|Thri...|\n",
            "|      7|      Sabrina (1995)|      Comedy|Romance|\n",
            "|      8| Tom and Huck (1995)|  Adventure|Children|\n",
            "|      9| Sudden Death (1995)|              Action|\n",
            "|     10|    GoldenEye (1995)|Action|Adventure|...|\n",
            "|     11|American Presiden...|Comedy|Drama|Romance|\n",
            "|     12|Dracula: Dead and...|       Comedy|Horror|\n",
            "|     13|        Balto (1995)|Adventure|Animati...|\n",
            "|     14|        Nixon (1995)|               Drama|\n",
            "|     15|Cutthroat Island ...|Action|Adventure|...|\n",
            "|     16|       Casino (1995)|         Crime|Drama|\n",
            "|     17|Sense and Sensibi...|       Drama|Romance|\n",
            "|     18|   Four Rooms (1995)|              Comedy|\n",
            "|     19|Ace Ventura: When...|              Comedy|\n",
            "|     20|  Money Train (1995)|Action|Comedy|Cri...|\n",
            "+-------+--------------------+--------------------+\n",
            "only showing top 20 rows\n",
            "\n",
            "Total Records in df_movies : 9742\n",
            "\n",
            "df_ratings\n",
            "+------+-------+------+---------+\n",
            "|userId|movieId|rating|timestamp|\n",
            "+------+-------+------+---------+\n",
            "|     1|      1|   4.0|964982703|\n",
            "|     1|      3|   4.0|964981247|\n",
            "|     1|      6|   4.0|964982224|\n",
            "|     1|     47|   5.0|964983815|\n",
            "|     1|     50|   5.0|964982931|\n",
            "|     1|     70|   3.0|964982400|\n",
            "|     1|    101|   5.0|964980868|\n",
            "|     1|    110|   4.0|964982176|\n",
            "|     1|    151|   5.0|964984041|\n",
            "|     1|    157|   5.0|964984100|\n",
            "|     1|    163|   5.0|964983650|\n",
            "|     1|    216|   5.0|964981208|\n",
            "|     1|    223|   3.0|964980985|\n",
            "|     1|    231|   5.0|964981179|\n",
            "|     1|    235|   4.0|964980908|\n",
            "|     1|    260|   5.0|964981680|\n",
            "|     1|    296|   3.0|964982967|\n",
            "|     1|    316|   3.0|964982310|\n",
            "|     1|    333|   5.0|964981179|\n",
            "|     1|    349|   4.0|964982563|\n",
            "+------+-------+------+---------+\n",
            "only showing top 20 rows\n",
            "\n",
            "Total Records in df_ratings : 100836\n",
            "\n",
            "df_tags\n",
            "+------+-------+-----------------+----------+\n",
            "|userId|movieId|              tag| timestamp|\n",
            "+------+-------+-----------------+----------+\n",
            "|     2|  60756|            funny|1445714994|\n",
            "|     2|  60756|  Highly quotable|1445714996|\n",
            "|     2|  60756|     will ferrell|1445714992|\n",
            "|     2|  89774|     Boxing story|1445715207|\n",
            "|     2|  89774|              MMA|1445715200|\n",
            "|     2|  89774|        Tom Hardy|1445715205|\n",
            "|     2| 106782|            drugs|1445715054|\n",
            "|     2| 106782|Leonardo DiCaprio|1445715051|\n",
            "|     2| 106782|  Martin Scorsese|1445715056|\n",
            "|     7|  48516|     way too long|1169687325|\n",
            "|    18|    431|        Al Pacino|1462138765|\n",
            "|    18|    431|         gangster|1462138749|\n",
            "|    18|    431|            mafia|1462138755|\n",
            "|    18|   1221|        Al Pacino|1461699306|\n",
            "|    18|   1221|            Mafia|1461699303|\n",
            "|    18|   5995|        holocaust|1455735472|\n",
            "|    18|   5995|       true story|1455735479|\n",
            "|    18|  44665|     twist ending|1456948283|\n",
            "|    18|  52604|  Anthony Hopkins|1457650696|\n",
            "|    18|  52604|  courtroom drama|1457650711|\n",
            "+------+-------+-----------------+----------+\n",
            "only showing top 20 rows\n",
            "\n",
            "Total Records in df_tags : 3683\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IGx4hRHsliOt",
        "outputId": "99d398fc-bc5b-46c9-bfee-5a296c0cda88"
      },
      "source": [
        "#PrintSchema of all the dataframe\n",
        "for name,df in df_dict.items():\n",
        "  print(name, 'Schema:')\n",
        "  df.printSchema()"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "df_links Schema:\nroot\n |-- movieId: integer (nullable = true)\n |-- imdbId: integer (nullable = true)\n |-- tmdbId: integer (nullable = true)\n\ndf_movies Schema:\nroot\n |-- movieId: integer (nullable = true)\n |-- title: string (nullable = true)\n |-- genres: string (nullable = true)\n\ndf_ratings Schema:\nroot\n |-- userId: integer (nullable = true)\n |-- movieId: integer (nullable = true)\n |-- rating: double (nullable = true)\n |-- timestamp: integer (nullable = true)\n\ndf_tags Schema:\nroot\n |-- userId: integer (nullable = true)\n |-- movieId: integer (nullable = true)\n |-- tag: string (nullable = true)\n |-- timestamp: integer (nullable = true)\n\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9HN5Y2jntE-O",
        "outputId": "0b486572-62a0-4b9f-e10a-02ba129bd16a"
      },
      "source": [
        "df_ratings"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "DataFrame[userId: int, movieId: int, rating: double, timestamp: int]"
            ]
          },
          "metadata": {},
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lkU0M8F5oa-a"
      },
      "source": [
        "#We noticed the datatype of the timestamp columns on both df_ratings and df_tags are integer\n",
        "#We need to change the datatype to timestamp\n",
        "df_ratings = df_ratings.withColumn('timestamp', f.date_format(df_ratings.timestamp.cast(dataType=t.TimestampType()), \"yyyy-MM-dd\"))\n",
        "df_ratings = df_ratings.withColumn('timestamp', f.to_date(df_ratings.timestamp.cast(dataType=t.TimestampType())))\n",
        "\n",
        "df_tags = df_tags.withColumn('timestamp', f.date_format(df_tags.timestamp.cast(dataType=t.TimestampType()), \"yyyy-MM-dd\"))\n",
        "df_tags = df_tags.withColumn('timestamp', f.to_date(df_tags.timestamp.cast(dataType=t.TimestampType())))\n"
      ],
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sK9NSohOvsps",
        "outputId": "f7752bfa-ce47-4747-d644-2325a6b7b0d8"
      },
      "source": [
        "df_ratings.printSchema()\n",
        "df_tags.printSchema()"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "root\n |-- userId: integer (nullable = true)\n |-- movieId: integer (nullable = true)\n |-- rating: double (nullable = true)\n |-- timestamp: date (nullable = true)\n\nroot\n |-- userId: integer (nullable = true)\n |-- movieId: integer (nullable = true)\n |-- tag: string (nullable = true)\n |-- timestamp: date (nullable = true)\n\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Qiy0aFsTsIRD"
      },
      "source": [
        "#Function that check the Nan & Null value in the whole dataframe \n",
        "def checkdfnan (df):\n",
        "  df = df.select([count(when(isnan(c) | col(c).isNull(), c)).alias(c) for c in df.columns]).show()\n",
        "  return df "
      ],
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Gu9oo06Vq0Cm",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "18184b3c-b87d-4a89-d14f-9a1d0d66c2d4"
      },
      "source": [
        "for key,value in df_dict.items():\n",
        "  print(key)\n",
        "  checkdfnan(value)"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "df_links\n",
            "+-------+------+------+\n",
            "|movieId|imdbId|tmdbId|\n",
            "+-------+------+------+\n",
            "|      0|     0|     8|\n",
            "+-------+------+------+\n",
            "\n",
            "df_movies\n",
            "+-------+-----+------+\n",
            "|movieId|title|genres|\n",
            "+-------+-----+------+\n",
            "|      0|    0|     0|\n",
            "+-------+-----+------+\n",
            "\n",
            "df_ratings\n",
            "+------+-------+------+---------+\n",
            "|userId|movieId|rating|timestamp|\n",
            "+------+-------+------+---------+\n",
            "|     0|      0|     0|        0|\n",
            "+------+-------+------+---------+\n",
            "\n",
            "df_tags\n",
            "+------+-------+---+---------+\n",
            "|userId|movieId|tag|timestamp|\n",
            "+------+-------+---+---------+\n",
            "|     0|      0|  0|        0|\n",
            "+------+-------+---+---------+\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JGj_4xwhs1zu",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "eef37e8a-8b53-4c5f-841d-9019463ddec2"
      },
      "source": [
        "df_links.show()"
      ],
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+-------+------+------+\n|movieId|imdbId|tmdbId|\n+-------+------+------+\n|      1|114709|   862|\n|      2|113497|  8844|\n|      3|113228| 15602|\n|      4|114885| 31357|\n|      5|113041| 11862|\n|      6|113277|   949|\n|      7|114319| 11860|\n|      8|112302| 45325|\n|      9|114576|  9091|\n|     10|113189|   710|\n|     11|112346|  9087|\n|     12|112896| 12110|\n|     13|112453| 21032|\n|     14|113987| 10858|\n|     15|112760|  1408|\n|     16|112641|   524|\n|     17|114388|  4584|\n|     18|113101|     5|\n|     19|112281|  9273|\n|     20|113845| 11517|\n+-------+------+------+\nonly showing top 20 rows\n\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "aA4MA2jG0KL4",
        "outputId": "4a954e73-6c10-4a8e-eb58-0eb0ddbe6c84"
      },
      "source": [
        "df_movies.show()"
      ],
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+-------+--------------------+--------------------+\n|movieId|               title|              genres|\n+-------+--------------------+--------------------+\n|      1|    Toy Story (1995)|Adventure|Animati...|\n|      2|      Jumanji (1995)|Adventure|Childre...|\n|      3|Grumpier Old Men ...|      Comedy|Romance|\n|      4|Waiting to Exhale...|Comedy|Drama|Romance|\n|      5|Father of the Bri...|              Comedy|\n|      6|         Heat (1995)|Action|Crime|Thri...|\n|      7|      Sabrina (1995)|      Comedy|Romance|\n|      8| Tom and Huck (1995)|  Adventure|Children|\n|      9| Sudden Death (1995)|              Action|\n|     10|    GoldenEye (1995)|Action|Adventure|...|\n|     11|American Presiden...|Comedy|Drama|Romance|\n|     12|Dracula: Dead and...|       Comedy|Horror|\n|     13|        Balto (1995)|Adventure|Animati...|\n|     14|        Nixon (1995)|               Drama|\n|     15|Cutthroat Island ...|Action|Adventure|...|\n|     16|       Casino (1995)|         Crime|Drama|\n|     17|Sense and Sensibi...|       Drama|Romance|\n|     18|   Four Rooms (1995)|              Comedy|\n|     19|Ace Ventura: When...|              Comedy|\n|     20|  Money Train (1995)|Action|Comedy|Cri...|\n+-------+--------------------+--------------------+\nonly showing top 20 rows\n\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NMMv5FvI0a1X",
        "outputId": "8eac3d9d-358d-4ec0-b55f-65a352ac61b1"
      },
      "source": [
        "df_movies_ratings = df_movies.join(df_ratings, df_movies.movieId == df_ratings.movieId, 'inner').drop(df_movies.movieId)\r\n",
        "df_movies_ratings.show()"
      ],
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+--------------------+--------------------+------+-------+------+----------+\n|               title|              genres|userId|movieId|rating| timestamp|\n+--------------------+--------------------+------+-------+------+----------+\n|    Toy Story (1995)|Adventure|Animati...|     1|      1|   4.0|2000-07-30|\n|Grumpier Old Men ...|      Comedy|Romance|     1|      3|   4.0|2000-07-30|\n|         Heat (1995)|Action|Crime|Thri...|     1|      6|   4.0|2000-07-30|\n|Seven (a.k.a. Se7...|    Mystery|Thriller|     1|     47|   5.0|2000-07-30|\n|Usual Suspects, T...|Crime|Mystery|Thr...|     1|     50|   5.0|2000-07-30|\n|From Dusk Till Da...|Action|Comedy|Hor...|     1|     70|   3.0|2000-07-30|\n|Bottle Rocket (1996)|Adventure|Comedy|...|     1|    101|   5.0|2000-07-30|\n|   Braveheart (1995)|    Action|Drama|War|     1|    110|   4.0|2000-07-30|\n|      Rob Roy (1995)|Action|Drama|Roma...|     1|    151|   5.0|2000-07-30|\n|Canadian Bacon (1...|          Comedy|War|     1|    157|   5.0|2000-07-30|\n|    Desperado (1995)|Action|Romance|We...|     1|    163|   5.0|2000-07-30|\n|Billy Madison (1995)|              Comedy|     1|    216|   5.0|2000-07-30|\n|       Clerks (1994)|              Comedy|     1|    223|   3.0|2000-07-30|\n|Dumb & Dumber (Du...|    Adventure|Comedy|     1|    231|   5.0|2000-07-30|\n|      Ed Wood (1994)|        Comedy|Drama|     1|    235|   4.0|2000-07-30|\n|Star Wars: Episod...|Action|Adventure|...|     1|    260|   5.0|2000-07-30|\n| Pulp Fiction (1994)|Comedy|Crime|Dram...|     1|    296|   3.0|2000-07-30|\n|     Stargate (1994)|Action|Adventure|...|     1|    316|   3.0|2000-07-30|\n|    Tommy Boy (1995)|              Comedy|     1|    333|   5.0|2000-07-30|\n|Clear and Present...|Action|Crime|Dram...|     1|    349|   4.0|2000-07-30|\n+--------------------+--------------------+------+-------+------+----------+\nonly showing top 20 rows\n\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gjLl9hna0apa",
        "outputId": "a7b6df41-225b-4473-c183-2557edf24c29"
      },
      "source": [
        "df_movies_ratings.count()"
      ],
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "100836"
            ]
          },
          "metadata": {},
          "execution_count": 16
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fS1-9KMVA9y9"
      },
      "source": [
        "df_tags.show()"
      ],
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+------+-------+-----------------+----------+\n|userId|movieId|              tag| timestamp|\n+------+-------+-----------------+----------+\n|     2|  60756|            funny|2015-10-24|\n|     2|  60756|  Highly quotable|2015-10-24|\n|     2|  60756|     will ferrell|2015-10-24|\n|     2|  89774|     Boxing story|2015-10-24|\n|     2|  89774|              MMA|2015-10-24|\n|     2|  89774|        Tom Hardy|2015-10-24|\n|     2| 106782|            drugs|2015-10-24|\n|     2| 106782|Leonardo DiCaprio|2015-10-24|\n|     2| 106782|  Martin Scorsese|2015-10-24|\n|     7|  48516|     way too long|2007-01-24|\n|    18|    431|        Al Pacino|2016-05-01|\n|    18|    431|         gangster|2016-05-01|\n|    18|    431|            mafia|2016-05-01|\n|    18|   1221|        Al Pacino|2016-04-26|\n|    18|   1221|            Mafia|2016-04-26|\n|    18|   5995|        holocaust|2016-02-17|\n|    18|   5995|       true story|2016-02-17|\n|    18|  44665|     twist ending|2016-03-02|\n|    18|  52604|  Anthony Hopkins|2016-03-10|\n|    18|  52604|  courtroom drama|2016-03-10|\n+------+-------+-----------------+----------+\nonly showing top 20 rows\n\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mkfXtHgQA91j"
      },
      "source": [
        "df_movies_ratings.show()"
      ],
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+--------------------+--------------------+------+-------+------+----------+\n|               title|              genres|userId|movieId|rating| timestamp|\n+--------------------+--------------------+------+-------+------+----------+\n|    Toy Story (1995)|Adventure|Animati...|     1|      1|   4.0|2000-07-30|\n|Grumpier Old Men ...|      Comedy|Romance|     1|      3|   4.0|2000-07-30|\n|         Heat (1995)|Action|Crime|Thri...|     1|      6|   4.0|2000-07-30|\n|Seven (a.k.a. Se7...|    Mystery|Thriller|     1|     47|   5.0|2000-07-30|\n|Usual Suspects, T...|Crime|Mystery|Thr...|     1|     50|   5.0|2000-07-30|\n|From Dusk Till Da...|Action|Comedy|Hor...|     1|     70|   3.0|2000-07-30|\n|Bottle Rocket (1996)|Adventure|Comedy|...|     1|    101|   5.0|2000-07-30|\n|   Braveheart (1995)|    Action|Drama|War|     1|    110|   4.0|2000-07-30|\n|      Rob Roy (1995)|Action|Drama|Roma...|     1|    151|   5.0|2000-07-30|\n|Canadian Bacon (1...|          Comedy|War|     1|    157|   5.0|2000-07-30|\n|    Desperado (1995)|Action|Romance|We...|     1|    163|   5.0|2000-07-30|\n|Billy Madison (1995)|              Comedy|     1|    216|   5.0|2000-07-30|\n|       Clerks (1994)|              Comedy|     1|    223|   3.0|2000-07-30|\n|Dumb & Dumber (Du...|    Adventure|Comedy|     1|    231|   5.0|2000-07-30|\n|      Ed Wood (1994)|        Comedy|Drama|     1|    235|   4.0|2000-07-30|\n|Star Wars: Episod...|Action|Adventure|...|     1|    260|   5.0|2000-07-30|\n| Pulp Fiction (1994)|Comedy|Crime|Dram...|     1|    296|   3.0|2000-07-30|\n|     Stargate (1994)|Action|Adventure|...|     1|    316|   3.0|2000-07-30|\n|    Tommy Boy (1995)|              Comedy|     1|    333|   5.0|2000-07-30|\n|Clear and Present...|Action|Crime|Dram...|     1|    349|   4.0|2000-07-30|\n+--------------------+--------------------+------+-------+------+----------+\nonly showing top 20 rows\n\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {},
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+------+-------+------+\n|userID|movieId|rating|\n+------+-------+------+\n|     1|      1|   4.0|\n|     1|      3|   4.0|\n|     1|      6|   4.0|\n|     1|     47|   5.0|\n|     1|     50|   5.0|\n|     1|     70|   3.0|\n|     1|    101|   5.0|\n|     1|    110|   4.0|\n|     1|    151|   5.0|\n|     1|    157|   5.0|\n|     1|    163|   5.0|\n|     1|    216|   5.0|\n|     1|    223|   3.0|\n|     1|    231|   5.0|\n|     1|    235|   4.0|\n|     1|    260|   5.0|\n|     1|    296|   3.0|\n|     1|    316|   3.0|\n|     1|    333|   5.0|\n|     1|    349|   4.0|\n+------+-------+------+\nonly showing top 20 rows\n\n"
          ]
        }
      ],
      "source": [
        "#getting the data that is needed from df_rating_movie\n",
        "data = df_movies_ratings.select('userID','movieId','rating')\n",
        "data.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "metadata": {},
      "outputs": [
        {
          "output_type": "error",
          "ename": "Py4JJavaError",
          "evalue": "An error occurred while calling o323.trainALSModel.\n: org.apache.spark.SparkException: Job aborted due to stage failure: Task 0 in stage 45.0 failed 1 times, most recent failure: Lost task 0.0 in stage 45.0 (TID 45) (MSI executor driver): org.apache.spark.api.python.PythonException: Traceback (most recent call last):\n  File \"C:\\Python\\Python39\\Lib\\site-packages\\pyspark\\python\\lib\\pyspark.zip\\pyspark\\worker.py\", line 586, in main\n  File \"C:\\Python\\Python39\\Lib\\site-packages\\pyspark\\python\\lib\\pyspark.zip\\pyspark\\worker.py\", line 69, in read_command\n  File \"C:\\Python\\Python39\\Lib\\site-packages\\pyspark\\python\\lib\\pyspark.zip\\pyspark\\serializers.py\", line 160, in _read_with_length\n    return self.loads(obj)\n  File \"C:\\Python\\Python39\\Lib\\site-packages\\pyspark\\python\\lib\\pyspark.zip\\pyspark\\serializers.py\", line 430, in loads\n    return pickle.loads(obj, encoding=encoding)\n  File \"<frozen zipimport>\", line 259, in load_module\n  File \"C:\\Python\\Python39\\Lib\\site-packages\\pyspark\\python\\lib\\pyspark.zip\\pyspark\\mllib\\__init__.py\", line 26, in <module>\n    import numpy\nModuleNotFoundError: No module named 'numpy'\n\r\n\tat org.apache.spark.api.python.BasePythonRunner$ReaderIterator.handlePythonException(PythonRunner.scala:517)\r\n\tat org.apache.spark.api.python.PythonRunner$$anon$3.read(PythonRunner.scala:652)\r\n\tat org.apache.spark.api.python.PythonRunner$$anon$3.read(PythonRunner.scala:635)\r\n\tat org.apache.spark.api.python.BasePythonRunner$ReaderIterator.hasNext(PythonRunner.scala:470)\r\n\tat org.apache.spark.InterruptibleIterator.hasNext(InterruptibleIterator.scala:37)\r\n\tat scala.collection.Iterator$$anon$11.hasNext(Iterator.scala:489)\r\n\tat scala.collection.Iterator$SliceIterator.hasNext(Iterator.scala:266)\r\n\tat scala.collection.Iterator.foreach(Iterator.scala:941)\r\n\tat scala.collection.Iterator.foreach$(Iterator.scala:941)\r\n\tat scala.collection.AbstractIterator.foreach(Iterator.scala:1429)\r\n\tat scala.collection.generic.Growable.$plus$plus$eq(Growable.scala:62)\r\n\tat scala.collection.generic.Growable.$plus$plus$eq$(Growable.scala:53)\r\n\tat scala.collection.mutable.ArrayBuffer.$plus$plus$eq(ArrayBuffer.scala:105)\r\n\tat scala.collection.mutable.ArrayBuffer.$plus$plus$eq(ArrayBuffer.scala:49)\r\n\tat scala.collection.TraversableOnce.to(TraversableOnce.scala:315)\r\n\tat scala.collection.TraversableOnce.to$(TraversableOnce.scala:313)\r\n\tat scala.collection.AbstractIterator.to(Iterator.scala:1429)\r\n\tat scala.collection.TraversableOnce.toBuffer(TraversableOnce.scala:307)\r\n\tat scala.collection.TraversableOnce.toBuffer$(TraversableOnce.scala:307)\r\n\tat scala.collection.AbstractIterator.toBuffer(Iterator.scala:1429)\r\n\tat scala.collection.TraversableOnce.toArray(TraversableOnce.scala:294)\r\n\tat scala.collection.TraversableOnce.toArray$(TraversableOnce.scala:288)\r\n\tat scala.collection.AbstractIterator.toArray(Iterator.scala:1429)\r\n\tat org.apache.spark.rdd.RDD.$anonfun$take$2(RDD.scala:1449)\r\n\tat org.apache.spark.SparkContext.$anonfun$runJob$5(SparkContext.scala:2242)\r\n\tat org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:90)\r\n\tat org.apache.spark.scheduler.Task.run(Task.scala:131)\r\n\tat org.apache.spark.executor.Executor$TaskRunner.$anonfun$run$3(Executor.scala:497)\r\n\tat org.apache.spark.util.Utils$.tryWithSafeFinally(Utils.scala:1439)\r\n\tat org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:500)\r\n\tat java.util.concurrent.ThreadPoolExecutor.runWorker(Unknown Source)\r\n\tat java.util.concurrent.ThreadPoolExecutor$Worker.run(Unknown Source)\r\n\tat java.lang.Thread.run(Unknown Source)\r\n\nDriver stacktrace:\r\n\tat org.apache.spark.scheduler.DAGScheduler.failJobAndIndependentStages(DAGScheduler.scala:2253)\r\n\tat org.apache.spark.scheduler.DAGScheduler.$anonfun$abortStage$2(DAGScheduler.scala:2202)\r\n\tat org.apache.spark.scheduler.DAGScheduler.$anonfun$abortStage$2$adapted(DAGScheduler.scala:2201)\r\n\tat scala.collection.mutable.ResizableArray.foreach(ResizableArray.scala:62)\r\n\tat scala.collection.mutable.ResizableArray.foreach$(ResizableArray.scala:55)\r\n\tat scala.collection.mutable.ArrayBuffer.foreach(ArrayBuffer.scala:49)\r\n\tat org.apache.spark.scheduler.DAGScheduler.abortStage(DAGScheduler.scala:2201)\r\n\tat org.apache.spark.scheduler.DAGScheduler.$anonfun$handleTaskSetFailed$1(DAGScheduler.scala:1078)\r\n\tat org.apache.spark.scheduler.DAGScheduler.$anonfun$handleTaskSetFailed$1$adapted(DAGScheduler.scala:1078)\r\n\tat scala.Option.foreach(Option.scala:407)\r\n\tat org.apache.spark.scheduler.DAGScheduler.handleTaskSetFailed(DAGScheduler.scala:1078)\r\n\tat org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.doOnReceive(DAGScheduler.scala:2440)\r\n\tat org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.onReceive(DAGScheduler.scala:2382)\r\n\tat org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.onReceive(DAGScheduler.scala:2371)\r\n\tat org.apache.spark.util.EventLoop$$anon$1.run(EventLoop.scala:49)\r\n\tat org.apache.spark.scheduler.DAGScheduler.runJob(DAGScheduler.scala:868)\r\n\tat org.apache.spark.SparkContext.runJob(SparkContext.scala:2202)\r\n\tat org.apache.spark.SparkContext.runJob(SparkContext.scala:2223)\r\n\tat org.apache.spark.SparkContext.runJob(SparkContext.scala:2242)\r\n\tat org.apache.spark.rdd.RDD.$anonfun$take$1(RDD.scala:1449)\r\n\tat org.apache.spark.rdd.RDDOperationScope$.withScope(RDDOperationScope.scala:151)\r\n\tat org.apache.spark.rdd.RDDOperationScope$.withScope(RDDOperationScope.scala:112)\r\n\tat org.apache.spark.rdd.RDD.withScope(RDD.scala:414)\r\n\tat org.apache.spark.rdd.RDD.take(RDD.scala:1422)\r\n\tat org.apache.spark.rdd.RDD.$anonfun$isEmpty$1(RDD.scala:1557)\r\n\tat scala.runtime.java8.JFunction0$mcZ$sp.apply(JFunction0$mcZ$sp.java:23)\r\n\tat org.apache.spark.rdd.RDDOperationScope$.withScope(RDDOperationScope.scala:151)\r\n\tat org.apache.spark.rdd.RDDOperationScope$.withScope(RDDOperationScope.scala:112)\r\n\tat org.apache.spark.rdd.RDD.withScope(RDD.scala:414)\r\n\tat org.apache.spark.rdd.RDD.isEmpty(RDD.scala:1557)\r\n\tat org.apache.spark.mllib.recommendation.ALS.run(ALS.scala:241)\r\n\tat org.apache.spark.mllib.api.python.PythonMLLibAPI.trainALSModel(PythonMLLibAPI.scala:483)\r\n\tat sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)\r\n\tat sun.reflect.NativeMethodAccessorImpl.invoke(Unknown Source)\r\n\tat sun.reflect.DelegatingMethodAccessorImpl.invoke(Unknown Source)\r\n\tat java.lang.reflect.Method.invoke(Unknown Source)\r\n\tat py4j.reflection.MethodInvoker.invoke(MethodInvoker.java:244)\r\n\tat py4j.reflection.ReflectionEngine.invoke(ReflectionEngine.java:357)\r\n\tat py4j.Gateway.invoke(Gateway.java:282)\r\n\tat py4j.commands.AbstractCommand.invokeMethod(AbstractCommand.java:132)\r\n\tat py4j.commands.CallCommand.execute(CallCommand.java:79)\r\n\tat py4j.GatewayConnection.run(GatewayConnection.java:238)\r\n\tat java.lang.Thread.run(Unknown Source)\r\nCaused by: org.apache.spark.api.python.PythonException: Traceback (most recent call last):\n  File \"C:\\Python\\Python39\\Lib\\site-packages\\pyspark\\python\\lib\\pyspark.zip\\pyspark\\worker.py\", line 586, in main\n  File \"C:\\Python\\Python39\\Lib\\site-packages\\pyspark\\python\\lib\\pyspark.zip\\pyspark\\worker.py\", line 69, in read_command\n  File \"C:\\Python\\Python39\\Lib\\site-packages\\pyspark\\python\\lib\\pyspark.zip\\pyspark\\serializers.py\", line 160, in _read_with_length\n    return self.loads(obj)\n  File \"C:\\Python\\Python39\\Lib\\site-packages\\pyspark\\python\\lib\\pyspark.zip\\pyspark\\serializers.py\", line 430, in loads\n    return pickle.loads(obj, encoding=encoding)\n  File \"<frozen zipimport>\", line 259, in load_module\n  File \"C:\\Python\\Python39\\Lib\\site-packages\\pyspark\\python\\lib\\pyspark.zip\\pyspark\\mllib\\__init__.py\", line 26, in <module>\n    import numpy\nModuleNotFoundError: No module named 'numpy'\n\r\n\tat org.apache.spark.api.python.BasePythonRunner$ReaderIterator.handlePythonException(PythonRunner.scala:517)\r\n\tat org.apache.spark.api.python.PythonRunner$$anon$3.read(PythonRunner.scala:652)\r\n\tat org.apache.spark.api.python.PythonRunner$$anon$3.read(PythonRunner.scala:635)\r\n\tat org.apache.spark.api.python.BasePythonRunner$ReaderIterator.hasNext(PythonRunner.scala:470)\r\n\tat org.apache.spark.InterruptibleIterator.hasNext(InterruptibleIterator.scala:37)\r\n\tat scala.collection.Iterator$$anon$11.hasNext(Iterator.scala:489)\r\n\tat scala.collection.Iterator$SliceIterator.hasNext(Iterator.scala:266)\r\n\tat scala.collection.Iterator.foreach(Iterator.scala:941)\r\n\tat scala.collection.Iterator.foreach$(Iterator.scala:941)\r\n\tat scala.collection.AbstractIterator.foreach(Iterator.scala:1429)\r\n\tat scala.collection.generic.Growable.$plus$plus$eq(Growable.scala:62)\r\n\tat scala.collection.generic.Growable.$plus$plus$eq$(Growable.scala:53)\r\n\tat scala.collection.mutable.ArrayBuffer.$plus$plus$eq(ArrayBuffer.scala:105)\r\n\tat scala.collection.mutable.ArrayBuffer.$plus$plus$eq(ArrayBuffer.scala:49)\r\n\tat scala.collection.TraversableOnce.to(TraversableOnce.scala:315)\r\n\tat scala.collection.TraversableOnce.to$(TraversableOnce.scala:313)\r\n\tat scala.collection.AbstractIterator.to(Iterator.scala:1429)\r\n\tat scala.collection.TraversableOnce.toBuffer(TraversableOnce.scala:307)\r\n\tat scala.collection.TraversableOnce.toBuffer$(TraversableOnce.scala:307)\r\n\tat scala.collection.AbstractIterator.toBuffer(Iterator.scala:1429)\r\n\tat scala.collection.TraversableOnce.toArray(TraversableOnce.scala:294)\r\n\tat scala.collection.TraversableOnce.toArray$(TraversableOnce.scala:288)\r\n\tat scala.collection.AbstractIterator.toArray(Iterator.scala:1429)\r\n\tat org.apache.spark.rdd.RDD.$anonfun$take$2(RDD.scala:1449)\r\n\tat org.apache.spark.SparkContext.$anonfun$runJob$5(SparkContext.scala:2242)\r\n\tat org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:90)\r\n\tat org.apache.spark.scheduler.Task.run(Task.scala:131)\r\n\tat org.apache.spark.executor.Executor$TaskRunner.$anonfun$run$3(Executor.scala:497)\r\n\tat org.apache.spark.util.Utils$.tryWithSafeFinally(Utils.scala:1439)\r\n\tat org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:500)\r\n\tat java.util.concurrent.ThreadPoolExecutor.runWorker(Unknown Source)\r\n\tat java.util.concurrent.ThreadPoolExecutor$Worker.run(Unknown Source)\r\n\t... 1 more\r\n",
          "traceback": [
            "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[1;31mPy4JJavaError\u001b[0m                             Traceback (most recent call last)",
            "\u001b[1;32m<ipython-input-21-62aea972ca9d>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      6\u001b[0m \u001b[0mrank\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;36m10\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      7\u001b[0m \u001b[0mnumIterations\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;36m10\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 8\u001b[1;33m \u001b[0mmodel\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mALS\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtrain\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mrank\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnumIterations\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[1;32mC:\\Python\\Python39\\lib\\site-packages\\pyspark\\mllib\\recommendation.py\u001b[0m in \u001b[0;36mtrain\u001b[1;34m(cls, ratings, rank, iterations, lambda_, blocks, nonnegative, seed)\u001b[0m\n\u001b[0;32m    278\u001b[0m             \u001b[1;33m(\u001b[0m\u001b[0mdefault\u001b[0m\u001b[1;33m:\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    279\u001b[0m         \"\"\"\n\u001b[1;32m--> 280\u001b[1;33m         model = callMLlibFunc(\"trainALSModel\", cls._prepare(ratings), rank, iterations,\n\u001b[0m\u001b[0;32m    281\u001b[0m                               lambda_, blocks, nonnegative, seed)\n\u001b[0;32m    282\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mMatrixFactorizationModel\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
            "\u001b[1;32mC:\\Python\\Python39\\lib\\site-packages\\pyspark\\mllib\\common.py\u001b[0m in \u001b[0;36mcallMLlibFunc\u001b[1;34m(name, *args)\u001b[0m\n\u001b[0;32m    123\u001b[0m     \u001b[0msc\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mSparkContext\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mgetOrCreate\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    124\u001b[0m     \u001b[0mapi\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mgetattr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msc\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_jvm\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mPythonMLLibAPI\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mname\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 125\u001b[1;33m     \u001b[1;32mreturn\u001b[0m \u001b[0mcallJavaFunc\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msc\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mapi\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    126\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    127\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
            "\u001b[1;32mC:\\Python\\Python39\\lib\\site-packages\\pyspark\\mllib\\common.py\u001b[0m in \u001b[0;36mcallJavaFunc\u001b[1;34m(sc, func, *args)\u001b[0m\n\u001b[0;32m    116\u001b[0m     \u001b[1;34m\"\"\" Call Java Function \"\"\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    117\u001b[0m     \u001b[0margs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[0m_py2java\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msc\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0ma\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0ma\u001b[0m \u001b[1;32min\u001b[0m \u001b[0margs\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 118\u001b[1;33m     \u001b[1;32mreturn\u001b[0m \u001b[0m_java2py\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msc\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfunc\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    119\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    120\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
            "\u001b[1;32mC:\\Python\\Python39\\lib\\site-packages\\py4j\\java_gateway.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, *args)\u001b[0m\n\u001b[0;32m   1302\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1303\u001b[0m         \u001b[0manswer\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mgateway_client\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msend_command\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcommand\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1304\u001b[1;33m         return_value = get_return_value(\n\u001b[0m\u001b[0;32m   1305\u001b[0m             answer, self.gateway_client, self.target_id, self.name)\n\u001b[0;32m   1306\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
            "\u001b[1;32mC:\\Python\\Python39\\lib\\site-packages\\pyspark\\sql\\utils.py\u001b[0m in \u001b[0;36mdeco\u001b[1;34m(*a, **kw)\u001b[0m\n\u001b[0;32m    109\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mdeco\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0ma\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkw\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    110\u001b[0m         \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 111\u001b[1;33m             \u001b[1;32mreturn\u001b[0m \u001b[0mf\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0ma\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkw\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    112\u001b[0m         \u001b[1;32mexcept\u001b[0m \u001b[0mpy4j\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mprotocol\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mPy4JJavaError\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    113\u001b[0m             \u001b[0mconverted\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mconvert_exception\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0me\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mjava_exception\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
            "\u001b[1;32mC:\\Python\\Python39\\lib\\site-packages\\py4j\\protocol.py\u001b[0m in \u001b[0;36mget_return_value\u001b[1;34m(answer, gateway_client, target_id, name)\u001b[0m\n\u001b[0;32m    324\u001b[0m             \u001b[0mvalue\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mOUTPUT_CONVERTER\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mtype\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0manswer\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m2\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mgateway_client\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    325\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0manswer\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m==\u001b[0m \u001b[0mREFERENCE_TYPE\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 326\u001b[1;33m                 raise Py4JJavaError(\n\u001b[0m\u001b[0;32m    327\u001b[0m                     \u001b[1;34m\"An error occurred while calling {0}{1}{2}.\\n\"\u001b[0m\u001b[1;33m.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    328\u001b[0m                     format(target_id, \".\", name), value)\n",
            "\u001b[1;31mPy4JJavaError\u001b[0m: An error occurred while calling o323.trainALSModel.\n: org.apache.spark.SparkException: Job aborted due to stage failure: Task 0 in stage 45.0 failed 1 times, most recent failure: Lost task 0.0 in stage 45.0 (TID 45) (MSI executor driver): org.apache.spark.api.python.PythonException: Traceback (most recent call last):\n  File \"C:\\Python\\Python39\\Lib\\site-packages\\pyspark\\python\\lib\\pyspark.zip\\pyspark\\worker.py\", line 586, in main\n  File \"C:\\Python\\Python39\\Lib\\site-packages\\pyspark\\python\\lib\\pyspark.zip\\pyspark\\worker.py\", line 69, in read_command\n  File \"C:\\Python\\Python39\\Lib\\site-packages\\pyspark\\python\\lib\\pyspark.zip\\pyspark\\serializers.py\", line 160, in _read_with_length\n    return self.loads(obj)\n  File \"C:\\Python\\Python39\\Lib\\site-packages\\pyspark\\python\\lib\\pyspark.zip\\pyspark\\serializers.py\", line 430, in loads\n    return pickle.loads(obj, encoding=encoding)\n  File \"<frozen zipimport>\", line 259, in load_module\n  File \"C:\\Python\\Python39\\Lib\\site-packages\\pyspark\\python\\lib\\pyspark.zip\\pyspark\\mllib\\__init__.py\", line 26, in <module>\n    import numpy\nModuleNotFoundError: No module named 'numpy'\n\r\n\tat org.apache.spark.api.python.BasePythonRunner$ReaderIterator.handlePythonException(PythonRunner.scala:517)\r\n\tat org.apache.spark.api.python.PythonRunner$$anon$3.read(PythonRunner.scala:652)\r\n\tat org.apache.spark.api.python.PythonRunner$$anon$3.read(PythonRunner.scala:635)\r\n\tat org.apache.spark.api.python.BasePythonRunner$ReaderIterator.hasNext(PythonRunner.scala:470)\r\n\tat org.apache.spark.InterruptibleIterator.hasNext(InterruptibleIterator.scala:37)\r\n\tat scala.collection.Iterator$$anon$11.hasNext(Iterator.scala:489)\r\n\tat scala.collection.Iterator$SliceIterator.hasNext(Iterator.scala:266)\r\n\tat scala.collection.Iterator.foreach(Iterator.scala:941)\r\n\tat scala.collection.Iterator.foreach$(Iterator.scala:941)\r\n\tat scala.collection.AbstractIterator.foreach(Iterator.scala:1429)\r\n\tat scala.collection.generic.Growable.$plus$plus$eq(Growable.scala:62)\r\n\tat scala.collection.generic.Growable.$plus$plus$eq$(Growable.scala:53)\r\n\tat scala.collection.mutable.ArrayBuffer.$plus$plus$eq(ArrayBuffer.scala:105)\r\n\tat scala.collection.mutable.ArrayBuffer.$plus$plus$eq(ArrayBuffer.scala:49)\r\n\tat scala.collection.TraversableOnce.to(TraversableOnce.scala:315)\r\n\tat scala.collection.TraversableOnce.to$(TraversableOnce.scala:313)\r\n\tat scala.collection.AbstractIterator.to(Iterator.scala:1429)\r\n\tat scala.collection.TraversableOnce.toBuffer(TraversableOnce.scala:307)\r\n\tat scala.collection.TraversableOnce.toBuffer$(TraversableOnce.scala:307)\r\n\tat scala.collection.AbstractIterator.toBuffer(Iterator.scala:1429)\r\n\tat scala.collection.TraversableOnce.toArray(TraversableOnce.scala:294)\r\n\tat scala.collection.TraversableOnce.toArray$(TraversableOnce.scala:288)\r\n\tat scala.collection.AbstractIterator.toArray(Iterator.scala:1429)\r\n\tat org.apache.spark.rdd.RDD.$anonfun$take$2(RDD.scala:1449)\r\n\tat org.apache.spark.SparkContext.$anonfun$runJob$5(SparkContext.scala:2242)\r\n\tat org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:90)\r\n\tat org.apache.spark.scheduler.Task.run(Task.scala:131)\r\n\tat org.apache.spark.executor.Executor$TaskRunner.$anonfun$run$3(Executor.scala:497)\r\n\tat org.apache.spark.util.Utils$.tryWithSafeFinally(Utils.scala:1439)\r\n\tat org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:500)\r\n\tat java.util.concurrent.ThreadPoolExecutor.runWorker(Unknown Source)\r\n\tat java.util.concurrent.ThreadPoolExecutor$Worker.run(Unknown Source)\r\n\tat java.lang.Thread.run(Unknown Source)\r\n\nDriver stacktrace:\r\n\tat org.apache.spark.scheduler.DAGScheduler.failJobAndIndependentStages(DAGScheduler.scala:2253)\r\n\tat org.apache.spark.scheduler.DAGScheduler.$anonfun$abortStage$2(DAGScheduler.scala:2202)\r\n\tat org.apache.spark.scheduler.DAGScheduler.$anonfun$abortStage$2$adapted(DAGScheduler.scala:2201)\r\n\tat scala.collection.mutable.ResizableArray.foreach(ResizableArray.scala:62)\r\n\tat scala.collection.mutable.ResizableArray.foreach$(ResizableArray.scala:55)\r\n\tat scala.collection.mutable.ArrayBuffer.foreach(ArrayBuffer.scala:49)\r\n\tat org.apache.spark.scheduler.DAGScheduler.abortStage(DAGScheduler.scala:2201)\r\n\tat org.apache.spark.scheduler.DAGScheduler.$anonfun$handleTaskSetFailed$1(DAGScheduler.scala:1078)\r\n\tat org.apache.spark.scheduler.DAGScheduler.$anonfun$handleTaskSetFailed$1$adapted(DAGScheduler.scala:1078)\r\n\tat scala.Option.foreach(Option.scala:407)\r\n\tat org.apache.spark.scheduler.DAGScheduler.handleTaskSetFailed(DAGScheduler.scala:1078)\r\n\tat org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.doOnReceive(DAGScheduler.scala:2440)\r\n\tat org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.onReceive(DAGScheduler.scala:2382)\r\n\tat org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.onReceive(DAGScheduler.scala:2371)\r\n\tat org.apache.spark.util.EventLoop$$anon$1.run(EventLoop.scala:49)\r\n\tat org.apache.spark.scheduler.DAGScheduler.runJob(DAGScheduler.scala:868)\r\n\tat org.apache.spark.SparkContext.runJob(SparkContext.scala:2202)\r\n\tat org.apache.spark.SparkContext.runJob(SparkContext.scala:2223)\r\n\tat org.apache.spark.SparkContext.runJob(SparkContext.scala:2242)\r\n\tat org.apache.spark.rdd.RDD.$anonfun$take$1(RDD.scala:1449)\r\n\tat org.apache.spark.rdd.RDDOperationScope$.withScope(RDDOperationScope.scala:151)\r\n\tat org.apache.spark.rdd.RDDOperationScope$.withScope(RDDOperationScope.scala:112)\r\n\tat org.apache.spark.rdd.RDD.withScope(RDD.scala:414)\r\n\tat org.apache.spark.rdd.RDD.take(RDD.scala:1422)\r\n\tat org.apache.spark.rdd.RDD.$anonfun$isEmpty$1(RDD.scala:1557)\r\n\tat scala.runtime.java8.JFunction0$mcZ$sp.apply(JFunction0$mcZ$sp.java:23)\r\n\tat org.apache.spark.rdd.RDDOperationScope$.withScope(RDDOperationScope.scala:151)\r\n\tat org.apache.spark.rdd.RDDOperationScope$.withScope(RDDOperationScope.scala:112)\r\n\tat org.apache.spark.rdd.RDD.withScope(RDD.scala:414)\r\n\tat org.apache.spark.rdd.RDD.isEmpty(RDD.scala:1557)\r\n\tat org.apache.spark.mllib.recommendation.ALS.run(ALS.scala:241)\r\n\tat org.apache.spark.mllib.api.python.PythonMLLibAPI.trainALSModel(PythonMLLibAPI.scala:483)\r\n\tat sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)\r\n\tat sun.reflect.NativeMethodAccessorImpl.invoke(Unknown Source)\r\n\tat sun.reflect.DelegatingMethodAccessorImpl.invoke(Unknown Source)\r\n\tat java.lang.reflect.Method.invoke(Unknown Source)\r\n\tat py4j.reflection.MethodInvoker.invoke(MethodInvoker.java:244)\r\n\tat py4j.reflection.ReflectionEngine.invoke(ReflectionEngine.java:357)\r\n\tat py4j.Gateway.invoke(Gateway.java:282)\r\n\tat py4j.commands.AbstractCommand.invokeMethod(AbstractCommand.java:132)\r\n\tat py4j.commands.CallCommand.execute(CallCommand.java:79)\r\n\tat py4j.GatewayConnection.run(GatewayConnection.java:238)\r\n\tat java.lang.Thread.run(Unknown Source)\r\nCaused by: org.apache.spark.api.python.PythonException: Traceback (most recent call last):\n  File \"C:\\Python\\Python39\\Lib\\site-packages\\pyspark\\python\\lib\\pyspark.zip\\pyspark\\worker.py\", line 586, in main\n  File \"C:\\Python\\Python39\\Lib\\site-packages\\pyspark\\python\\lib\\pyspark.zip\\pyspark\\worker.py\", line 69, in read_command\n  File \"C:\\Python\\Python39\\Lib\\site-packages\\pyspark\\python\\lib\\pyspark.zip\\pyspark\\serializers.py\", line 160, in _read_with_length\n    return self.loads(obj)\n  File \"C:\\Python\\Python39\\Lib\\site-packages\\pyspark\\python\\lib\\pyspark.zip\\pyspark\\serializers.py\", line 430, in loads\n    return pickle.loads(obj, encoding=encoding)\n  File \"<frozen zipimport>\", line 259, in load_module\n  File \"C:\\Python\\Python39\\Lib\\site-packages\\pyspark\\python\\lib\\pyspark.zip\\pyspark\\mllib\\__init__.py\", line 26, in <module>\n    import numpy\nModuleNotFoundError: No module named 'numpy'\n\r\n\tat org.apache.spark.api.python.BasePythonRunner$ReaderIterator.handlePythonException(PythonRunner.scala:517)\r\n\tat org.apache.spark.api.python.PythonRunner$$anon$3.read(PythonRunner.scala:652)\r\n\tat org.apache.spark.api.python.PythonRunner$$anon$3.read(PythonRunner.scala:635)\r\n\tat org.apache.spark.api.python.BasePythonRunner$ReaderIterator.hasNext(PythonRunner.scala:470)\r\n\tat org.apache.spark.InterruptibleIterator.hasNext(InterruptibleIterator.scala:37)\r\n\tat scala.collection.Iterator$$anon$11.hasNext(Iterator.scala:489)\r\n\tat scala.collection.Iterator$SliceIterator.hasNext(Iterator.scala:266)\r\n\tat scala.collection.Iterator.foreach(Iterator.scala:941)\r\n\tat scala.collection.Iterator.foreach$(Iterator.scala:941)\r\n\tat scala.collection.AbstractIterator.foreach(Iterator.scala:1429)\r\n\tat scala.collection.generic.Growable.$plus$plus$eq(Growable.scala:62)\r\n\tat scala.collection.generic.Growable.$plus$plus$eq$(Growable.scala:53)\r\n\tat scala.collection.mutable.ArrayBuffer.$plus$plus$eq(ArrayBuffer.scala:105)\r\n\tat scala.collection.mutable.ArrayBuffer.$plus$plus$eq(ArrayBuffer.scala:49)\r\n\tat scala.collection.TraversableOnce.to(TraversableOnce.scala:315)\r\n\tat scala.collection.TraversableOnce.to$(TraversableOnce.scala:313)\r\n\tat scala.collection.AbstractIterator.to(Iterator.scala:1429)\r\n\tat scala.collection.TraversableOnce.toBuffer(TraversableOnce.scala:307)\r\n\tat scala.collection.TraversableOnce.toBuffer$(TraversableOnce.scala:307)\r\n\tat scala.collection.AbstractIterator.toBuffer(Iterator.scala:1429)\r\n\tat scala.collection.TraversableOnce.toArray(TraversableOnce.scala:294)\r\n\tat scala.collection.TraversableOnce.toArray$(TraversableOnce.scala:288)\r\n\tat scala.collection.AbstractIterator.toArray(Iterator.scala:1429)\r\n\tat org.apache.spark.rdd.RDD.$anonfun$take$2(RDD.scala:1449)\r\n\tat org.apache.spark.SparkContext.$anonfun$runJob$5(SparkContext.scala:2242)\r\n\tat org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:90)\r\n\tat org.apache.spark.scheduler.Task.run(Task.scala:131)\r\n\tat org.apache.spark.executor.Executor$TaskRunner.$anonfun$run$3(Executor.scala:497)\r\n\tat org.apache.spark.util.Utils$.tryWithSafeFinally(Utils.scala:1439)\r\n\tat org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:500)\r\n\tat java.util.concurrent.ThreadPoolExecutor.runWorker(Unknown Source)\r\n\tat java.util.concurrent.ThreadPoolExecutor$Worker.run(Unknown Source)\r\n\t... 1 more\r\n"
          ]
        }
      ],
      "source": [
        "import numpy\n",
        "from pyspark.mllib.recommendation import ALS, MatrixFactorizationModel, Rating\n",
        "#Spliting the data into train and test sets\n",
        "X_train, X_test = data.randomSplit([0.8,0.2])\n",
        "\n",
        "#Training the model using ALS\n",
        "rank = 10\n",
        "numIterations = 10\n",
        "model = ALS.train(X_train, rank, numIterations)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 33,
      "metadata": {},
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: pyspark in c:\\python\\python39\\lib\\site-packages (3.1.1)Note: you may need to restart the kernel to use updated packages.\n",
            "WARNING: You are using pip version 20.2.3; however, version 21.0.1 is available.\n",
            "You should consider upgrading via the 'C:\\Python\\Python39\\python.exe -m pip install --upgrade pip' command.\n",
            "Requirement already satisfied: py4j==0.10.9 in c:\\python\\python39\\lib\\site-packages (from pyspark) (0.10.9)\n",
            "\n"
          ]
        }
      ],
      "source": [
        "pip install pyspark\n"
      ]
    }
  ]
}