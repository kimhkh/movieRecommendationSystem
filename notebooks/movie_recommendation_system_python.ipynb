{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "movie_recommendation_system_python.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "mount_file_id": "1egbvkbpWHm5BTH0GZ7u2H4T0MbKkq_tX",
      "authorship_tag": "ABX9TyM5+DZUC6/MQcPxeRyhiVtc",
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/kimhkh/movieRecommendationSystem/blob/Kam_branch/movie_recommendation_system_python.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Bdp3i8uvSKBu"
      },
      "source": [
        "pip install surprise"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "G2MOCe3MEQe-"
      },
      "source": [
        "pip install pytorch_lightning\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JeGjyhgX-vTc"
      },
      "source": [
        "from surprise import SVD, accuracy, SVDpp\n",
        "from surprise.model_selection import cross_validate\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import os\n",
        "from surprise import Reader, Dataset\n",
        "import seaborn as sns\n",
        "import matplotlib.pyplot as plt\n",
        "import time\n",
        "from surprise.model_selection import train_test_split\n",
        "from surprise import Reader, Dataset\n",
        "from surprise.model_selection import train_test_split\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "from tqdm import tqdm\n",
        "\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "from torch.utils.data import Dataset as d\n",
        "from torch.utils.data import DataLoader\n",
        "import pytorch_lightning as pl\n",
        "from datetime import datetime"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XDQu1JTq_A0T"
      },
      "source": [
        "df_rating = pd.read_csv('/content/drive/MyDrive/movielens1B/ratings.csv')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZkZGf19M_A2r"
      },
      "source": [
        "np.random.seed(123)\n",
        "rand_userIds = np.random.choice(df_rating['userId'].unique(), \n",
        "                                size=int(len(df_rating['userId'].unique())*0.2), \n",
        "                                replace=False)\n",
        "\n",
        "df_rating = df_rating.loc[df_rating['userId'].isin(rand_userIds)]\n",
        "\n",
        "print('There are {} rows of data from {} users'.format(len(df_rating), len(df_rating['userId'].unique())))\n",
        "df_rating[\"timestamp\"] = df_rating.timestamp.apply(lambda x: datetime.fromtimestamp(x / 1e3))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "l_jYSyTv_A5H"
      },
      "source": [
        "df_rating.head()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-OZ0gZlg_nWC"
      },
      "source": [
        "#Loading the df_rating from a pandas dataframe using load_from_df() method and reader object\n",
        "\n",
        "reader = Reader(rating_scale=(0.5,5))\n",
        "data = Dataset.load_from_df(df_rating[['userId', 'movieId', 'rating']], reader)\n",
        "trainset, testset = trainset, testset = train_test_split(data, test_size=0.20)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oYjPOEHb_nYk"
      },
      "source": [
        "#Using the SVD algorithm\n",
        "import time\n",
        "start = time.time()\n",
        "algo = SVD()\n",
        "#Train the algorithm on the trainset, and predict ratings for the testset\n",
        "algo.fit(trainset)\n",
        "predictions = algo.test(testset)\n",
        "accuracy.rmse(predictions)\n",
        "end = time.time()\n",
        "time = end-start\n",
        "print(time)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-RLKWUad_ndf"
      },
      "source": [
        "import time\n",
        "start1 = time.time()\n",
        "cross_validate(algo, data, measures = ['RMSE'],cv=5,verbose=True) \n",
        "end1 = time.time()\n",
        "time = end1-start1\n",
        "print(time)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RsxpDobxATWe"
      },
      "source": [
        "import time\n",
        "start = time.time()\n",
        "algo= SVDpp()\n",
        "algo.fit(trainset)\n",
        "predictions = algo.test(testset)\n",
        "accuracy.rmse(predictions)\n",
        "end = time.time()\n",
        "time = end-start\n",
        "print(time)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2zmDBeITATZK"
      },
      "source": [
        "import time\n",
        "start1 = time.time()\n",
        "cross_validate(algo, data, measures = ['RMSE'],cv=5,verbose=True) \n",
        "end1 = time.time()\n",
        "time = end1-start1\n",
        "print(time)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QcoW8btEklst"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YZ3sx2umdTZp"
      },
      "source": [
        "df_rating['rank_latest'] = df_rating.groupby(['userId'])['timestamp'] \\\n",
        "                                .rank(method='first', ascending=False)\n",
        "df_rating"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6EPvtj6UdTcQ"
      },
      "source": [
        "#Using earlier review for trainning, and using latest review for testing\n",
        "train_ratings = df_rating[df_rating['rank_latest'] != 1]\n",
        "test_ratings = df_rating[df_rating['rank_latest'] == 1]\n",
        "train_ratings"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "N82msTU9dTer"
      },
      "source": [
        "#Converting the dataset into an implicit feedback dataset\n",
        "#Binarize the ratings to 1 means the user has interacted with the movie\n",
        "train_ratings.loc[:, 'rating'] = 1\n",
        "train_ratings.sample(10)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4zq8AQ2ZdThb"
      },
      "source": [
        "# Generate negative samples to train our models\n",
        "# Get a list of all movie IDs\n",
        "all_movieIds = df_rating['movieId'].unique()\n",
        "\n",
        "# Placeholders that will hold the training data\n",
        "users, items, labels = [], [], []\n",
        "\n",
        "# This is the set of items that each user has interaction with\n",
        "user_item_set = set(zip(train_ratings['userId'], train_ratings['movieId']))\n",
        "\n",
        "# 4:1 ratio of negative to positive samples\n",
        "num_negatives = 4\n",
        "\n",
        "for (u, i) in tqdm(user_item_set):\n",
        "    users.append(u)\n",
        "    items.append(i)\n",
        "    labels.append(1) # items that the user has interacted with are positive\n",
        "    for _ in range(num_negatives):\n",
        "        # randomly select an item\n",
        "        negative_item = np.random.choice(all_movieIds) \n",
        "        # check that the user has not interacted with this item\n",
        "        while (u, negative_item) in user_item_set:\n",
        "            negative_item = np.random.choice(all_movieIds)\n",
        "        users.append(u)\n",
        "        items.append(negative_item)\n",
        "        labels.append(0) # items not interacted with are negative"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "soKoRYevdTjo"
      },
      "source": [
        "class MovieLensTrainDataset(Dataset):\n",
        "    \"\"\"MovieLens PyTorch Dataset for Training\n",
        "    \n",
        "    Args:\n",
        "        ratings (pd.DataFrame): Dataframe containing the movie ratings\n",
        "        all_movieIds (list): List containing all movieIds\n",
        "    \n",
        "    \"\"\"\n",
        "\n",
        "    def __init__(self, ratings, all_movieIds):\n",
        "        self.users, self.items, self.labels = self.get_dataset(ratings, all_movieIds)\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.users)\n",
        "  \n",
        "    def __getitem__(self, idx):\n",
        "        return self.users[idx], self.items[idx], self.labels[idx]\n",
        "\n",
        "    def get_dataset(self, ratings, all_movieIds):\n",
        "        users, items, labels = [], [], []\n",
        "        user_item_set = set(zip(ratings['userId'], ratings['movieId']))\n",
        "\n",
        "        num_negatives = 4\n",
        "        for u, i in user_item_set:\n",
        "            users.append(u)\n",
        "            items.append(i)\n",
        "            labels.append(1)\n",
        "            for _ in range(num_negatives):\n",
        "                negative_item = np.random.choice(all_movieIds)\n",
        "                while (u, negative_item) in user_item_set:\n",
        "                    negative_item = np.random.choice(all_movieIds)\n",
        "                users.append(u)\n",
        "                items.append(negative_item)\n",
        "                labels.append(0)\n",
        "\n",
        "        return torch.tensor(users), torch.tensor(items), torch.tensor(labels)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eESK7cX2dTmE"
      },
      "source": [
        "class NCF(pl.LightningModule):\n",
        "    \"\"\" Neural Collaborative Filtering (NCF)\n",
        "    \n",
        "        Args:\n",
        "            num_users (int): Number of unique users\n",
        "            num_items (int): Number of unique items\n",
        "            ratings (pd.DataFrame): Dataframe containing the movie ratings for training\n",
        "            all_movieIds (list): List containing all movieIds (train + test)\n",
        "    \"\"\"\n",
        "    \n",
        "    def __init__(self, num_users, num_items, ratings, all_movieIds):\n",
        "        super().__init__()\n",
        "        self.user_embedding = nn.Embedding(num_embeddings=num_users, embedding_dim=8)\n",
        "        self.item_embedding = nn.Embedding(num_embeddings=num_items, embedding_dim=8)\n",
        "        self.fc1 = nn.Linear(in_features=16, out_features=64)\n",
        "        self.fc2 = nn.Linear(in_features=64, out_features=32)\n",
        "        self.output = nn.Linear(in_features=32, out_features=1)\n",
        "        self.ratings = ratings\n",
        "        self.all_movieIds = all_movieIds\n",
        "        \n",
        "    def forward(self, user_input, item_input):\n",
        "        \n",
        "        # Pass through embedding layers\n",
        "        user_embedded = self.user_embedding(user_input)\n",
        "        item_embedded = self.item_embedding(item_input)\n",
        "\n",
        "        # Concat the two embedding layers\n",
        "        vector = torch.cat([user_embedded, item_embedded], dim=-1)\n",
        "\n",
        "        # Pass through dense layer\n",
        "        vector = nn.ReLU()(self.fc1(vector))\n",
        "        vector = nn.ReLU()(self.fc2(vector))\n",
        "\n",
        "        # Output layer\n",
        "        pred = nn.Sigmoid()(self.output(vector))\n",
        "\n",
        "        return pred\n",
        "    \n",
        "    def training_step(self, batch, batch_idx):\n",
        "        user_input, item_input, labels = batch\n",
        "        predicted_labels = self(user_input, item_input)\n",
        "        loss = nn.BCELoss()(predicted_labels, labels.view(-1, 1).float())\n",
        "        return loss\n",
        "\n",
        "    def configure_optimizers(self):\n",
        "        return torch.optim.Adam(self.parameters())\n",
        "\n",
        "    def train_dataloader(self):\n",
        "        return DataLoader(MovieLensTrainDataset(self.ratings, self.all_movieIds),\n",
        "                          batch_size=512, num_workers=1)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "x-Wsk-4-9RxE"
      },
      "source": [
        "num_users = df_rating['userId'].max()+1\n",
        "num_items = df_rating['movieId'].max()+1\n",
        "\n",
        "all_movieIds = df_rating['movieId'].unique()\n",
        "\n",
        "model = NCF(num_users, num_items, train_ratings, all_movieIds)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "13d49e4n9R5i"
      },
      "source": [
        "import time\n",
        "start = time.time()\n",
        "trainer = pl.Trainer(max_epochs=3, gpus=1, reload_dataloaders_every_epoch=True,\n",
        "                     progress_bar_refresh_rate=50, logger=False, checkpoint_callback=False)\n",
        "\n",
        "trainer.fit(model)\n",
        "end = time.time()\n",
        "time = end-start"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ejqlfzFNuX_7"
      },
      "source": [
        "print(time)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KS6gCp0i9R8T"
      },
      "source": [
        "# User-item pairs for testing\n",
        "\n",
        "test_user_item_set = set(zip(test_ratings['userId'], test_ratings['movieId']))\n",
        "\n",
        "# Dict of all items that are interacted with by each user\n",
        "user_interacted_items = df_rating.groupby('userId')['movieId'].apply(list).to_dict()\n",
        "\n",
        "hits = []\n",
        "for (u,i) in tqdm(test_user_item_set):\n",
        "    interacted_items = user_interacted_items[u]\n",
        "    not_interacted_items = set(all_movieIds) - set(interacted_items)\n",
        "    selected_not_interacted = list(np.random.choice(list(not_interacted_items), 99))\n",
        "    test_items = selected_not_interacted + [i]\n",
        "    \n",
        "    predicted_labels = np.squeeze(model(torch.tensor([u]*100), \n",
        "                                        torch.tensor(test_items)).detach().numpy())\n",
        "    \n",
        "    top10_items = [test_items[i] for i in np.argsort(predicted_labels)[::-1][0:10].tolist()]\n",
        "    \n",
        "    if i in top10_items:\n",
        "        hits.append(1)\n",
        "    else:\n",
        "        hits.append(0)\n",
        "        \n",
        "print(\"The accuracy of the recommended top 10 items that the user will interact is {:.2f}\".format(np.average(hits)))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cW49NlCJ9SBO"
      },
      "source": [
        "df = df_rating.groupby('userId')['movieId'].apply(list).to_dict()\n"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}